{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The default page will route to the form.html page where user can input\\nnecessary variables for machine learning'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import required packages\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "from flask import Flask, render_template\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.dates as mpdates\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import date\n",
    "from matplotlib.pylab import rcParams\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dropout,Dense\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.dates as mpl_dates\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nsepy import get_history\n",
    "rcParams[ 'figure.figsize' ]=20,10\n",
    "\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "app = Flask(__name__)\n",
    "\n",
    "\"\"\"The default page will route to the form.html page where user can input\n",
    "necessary variables for machine learning\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@app.route('/')\n",
    "def form():\n",
    "    return render_template('form.html')\n",
    "\n",
    "\n",
    "@app.route('/data', methods=['POST'])\n",
    "def hello():\n",
    "\n",
    "    def obtain_data(ticker, start, end):\n",
    "        # Enter the start and end dates using the method date(yyyy,m,dd)\n",
    "        stock = get_history(symbol=ticker, start=start, end=end, index=True)\n",
    "        df = stock.copy()\n",
    "        df = df.reset_index()\n",
    "\n",
    "        df.index = df.Date\n",
    "        return df\n",
    "\n",
    "    df = obtain_data('NIFTY', date(2020, 1, 1), date(2021, 5, 18))\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df.index)\n",
    "    df['Date'] = df['Date'].apply(mpl_dates.date2num)\n",
    "\n",
    "    df[\"Date\"] = pd.to_datetime(df.Date)\n",
    "    df.index = df['Date']\n",
    "\n",
    "    train_value = math.floor( len(df) * 0.9)\n",
    "    remain_value = math.floor(len(df) - train_value)\n",
    "\n",
    "    # open data\n",
    "    open_data = df.sort_index(ascending=True, axis=0)\n",
    "    new_open_dataset = pd.DataFrame(index=range(0, len(df)), columns=['Date', \"Open\"])\n",
    "    valid_open_data = pd.DataFrame(index=range(0, remain_value), columns=[\"Date\", \"Predictions\"])\n",
    "\n",
    "    for i in range(0, len(open_data)):\n",
    "        new_open_dataset[\"Date\"][i] = open_data['Date'][i]\n",
    "        new_open_dataset[\"Open\"][i] = open_data[\"Open\"][i]\n",
    "\n",
    "    new_open_dataset.index = new_open_dataset.Date\n",
    "    new_open_dataset.drop(\"Date\", axis=1, inplace=True)\n",
    "\n",
    "    final_open_dataset = new_open_dataset.values\n",
    "\n",
    "    train_open_data = final_open_dataset[0:, :0]\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_open_data = scaler.fit_transform(final_open_dataset)\n",
    "\n",
    "    x_train_open_data, y_train_open_data = [], []\n",
    "\n",
    "    for i in range(60, len(train_open_data)):\n",
    "        x_train_open_data.append(scaled_open_data[i - 60:i, 0])\n",
    "        y_train_open_data.append(scaled_open_data[i, 0])\n",
    "\n",
    "    x_train_open_data, y_train_open_data = np.array(x_train_open_data), np.array(y_train_open_data)\n",
    "\n",
    "    x_train_open_data = np.reshape(x_train_open_data, (x_train_open_data.shape[0], x_train_open_data.shape[1], 1))\n",
    "\n",
    "    # high data\n",
    "    high_data = df.sort_index(ascending=True, axis=0)\n",
    "    new_high_dataset = pd.DataFrame(index=range(0, len(df)), columns=['Date', \"High\"])\n",
    "\n",
    "    for i in range(0, len(high_data)):\n",
    "        new_high_dataset[\"Date\"][i] = high_data['Date'][i]\n",
    "        new_high_dataset[\"High\"][i] = high_data[\"High\"][i]\n",
    "\n",
    "    new_original_dataset = new_high_dataset.copy()\n",
    "    new_high_dataset.index = new_high_dataset.Date\n",
    "    new_high_dataset.drop(\"Date\", axis=1, inplace=True)\n",
    "\n",
    "    final_high_dataset = new_high_dataset.values\n",
    "\n",
    "    train_high_data = final_high_dataset[0:]\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_high_data = scaler.fit_transform(final_high_dataset)\n",
    "\n",
    "    x_train_high_data, y_train_high_data = [], []\n",
    "\n",
    "    for i in range(60, len(train_high_data)):\n",
    "        x_train_high_data.append(scaled_high_data[i - 60:i, 0])\n",
    "        y_train_high_data.append(scaled_high_data[i, 0])\n",
    "\n",
    "    x_train_high_data, y_train_high_data = np.array(x_train_high_data), np.array(y_train_high_data)\n",
    "\n",
    "    x_train_high_data = np.reshape(x_train_high_data, (x_train_high_data.shape[0], x_train_high_data.shape[1], 1))\n",
    "\n",
    "    # low data\n",
    "    low_data = df.sort_index(ascending=True, axis=0)\n",
    "    new_low_dataset = pd.DataFrame(index=range(0, len(df)), columns=['Date', \"Low\"])\n",
    "\n",
    "    for i in range(0, len(high_data)):\n",
    "        new_low_dataset[\"Date\"][i] = low_data['Date'][i]\n",
    "        new_low_dataset[\"Low\"][i] = low_data[\"Low\"][i]\n",
    "\n",
    "    new_prediction_dataset = new_low_dataset.copy()\n",
    "\n",
    "    new_low_dataset.index = new_low_dataset.Date\n",
    "    new_low_dataset.drop(\"Date\", axis=1, inplace=True)\n",
    "\n",
    "    final_low_dataset = new_low_dataset.values\n",
    "\n",
    "    train_low_data = final_low_dataset[0:]\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_low_data = scaler.fit_transform(final_low_dataset)\n",
    "    x_train_low_data, y_train_low_data = [], []\n",
    "\n",
    "    for i in range(60, len(train_low_data)):\n",
    "        x_train_low_data.append(scaled_low_data[i - 60:i, 0])\n",
    "        y_train_low_data.append(scaled_low_data[i, 0])\n",
    "\n",
    "    x_train_low_data, y_train_low_data = np.array(x_train_low_data), np.array(y_train_low_data)\n",
    "\n",
    "    x_train_low_data = np.reshape(x_train_low_data, (x_train_low_data.shape[0], x_train_low_data.shape[1], 1))\n",
    "\n",
    "    # close data\n",
    "\n",
    "    close_data = df.sort_index(ascending=True, axis=0)\n",
    "    new_close_dataset = pd.DataFrame(index=range(0, len(df)), columns=['Date', \"Close\"])\n",
    "\n",
    "    for i in range(0, len(close_data)):\n",
    "        new_close_dataset[\"Date\"][i] = close_data['Date'][i]\n",
    "        new_close_dataset[\"Close\"][i] = close_data[\"Close\"][i]\n",
    "\n",
    "    new_close_dataset.index = new_close_dataset.Date\n",
    "    new_close_dataset.drop(\"Date\", axis=1, inplace=True)\n",
    "\n",
    "    final_close_dataset = new_close_dataset.values\n",
    "\n",
    "    train_close_data = final_close_dataset[0:]\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_close_data = scaler.fit_transform(final_close_dataset)\n",
    "\n",
    "    x_train_close_data, y_train_close_data = [], []\n",
    "\n",
    "    for i in range(60, len(train_close_data)):\n",
    "        x_train_close_data.append(scaled_close_data[i - 60:i, 0])\n",
    "        y_train_close_data.append(scaled_close_data[i, 0])\n",
    "\n",
    "    x_train_close_data, y_train_close_data = np.array(x_train_close_data), np.array(y_train_close_data)\n",
    "\n",
    "    x_train_close_data = np.reshape(x_train_close_data, (x_train_close_data.shape[0], x_train_close_data.shape[1], 1))\n",
    "\n",
    "\n",
    "\n",
    "    # open\n",
    "    lstm_model=Sequential()\n",
    "    lstm_model.add(LSTM(units=50,return_sequences=True,input_shape=(x_train_open_data.shape[1],1)))\n",
    "    lstm_model.add(LSTM(units=50))\n",
    "    lstm_model.add(Dense(1))\n",
    "    lstm_model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "    lstm_model.fit(x_train_open_data,y_train_open_data,epochs=1,batch_size=1,verbose=2)\n",
    "\n",
    "    inputs_open_data=new_open_dataset[len(new_open_dataset)- remain_value -60:].values\n",
    "    inputs_open_data=inputs_open_data.reshape(-1,1)\n",
    "    inputs_open_data=scaler.transform(inputs_open_data)\n",
    "    print(len(new_open_dataset)- remain_value -60)\n",
    "\n",
    "    # high\n",
    "    lstm_model=Sequential()\n",
    "    lstm_model.add(LSTM(units=50,return_sequences=True,input_shape=(x_train_close_data.shape[1],1)))\n",
    "    lstm_model.add(LSTM(units=50))\n",
    "    lstm_model.add(Dense(1))\n",
    "\n",
    "    lstm_model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "    lstm_model.fit(x_train_high_data,y_train_high_data,epochs=1,batch_size=1,verbose=2)\n",
    "\n",
    "    inputs_high_data=new_high_dataset[len(new_high_dataset)- remain_value-60:].values\n",
    "    inputs_high_data=inputs_high_data.reshape(-1,1)\n",
    "    inputs_high_data=scaler.transform(inputs_high_data)\n",
    "\n",
    "    # low\n",
    "    lstm_model=Sequential()\n",
    "    lstm_model.add(LSTM(units=50,return_sequences=True,input_shape=(x_train_low_data.shape[1],1)))\n",
    "    lstm_model.add(LSTM(units=50))\n",
    "    lstm_model.add(Dense(1))\n",
    "\n",
    "    lstm_model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "    lstm_model.fit(x_train_low_data,y_train_low_data,epochs=1,batch_size=1,verbose=2)\n",
    "\n",
    "    inputs_low_data=new_low_dataset[len(new_low_dataset)- remain_value-60:].values\n",
    "    inputs_low_data=inputs_low_data.reshape(-1,1)\n",
    "    inputs_low_data=scaler.transform(inputs_low_data)\n",
    "\n",
    "\n",
    "\n",
    "    #close\n",
    "    lstm_model=Sequential()\n",
    "    lstm_model.add(LSTM(units=50,return_sequences=True,input_shape=(x_train_close_data.shape[1],1)))\n",
    "    lstm_model.add(LSTM(units=50))\n",
    "    lstm_model.add(Dense(1))\n",
    "\n",
    "    lstm_model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "    lstm_model.fit(x_train_close_data,y_train_close_data,epochs=1,batch_size=1,verbose=2)\n",
    "\n",
    "    inputs_close_data=new_close_dataset[len(new_close_dataset)- remain_value-60:].values\n",
    "    inputs_close_data=inputs_close_data.reshape(-1,1)\n",
    "    inputs_close_data=scaler.transform(inputs_close_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # open\n",
    "    X_open_test=[]\n",
    "    for i in range(60,inputs_open_data.shape[0]):\n",
    "        X_open_test.append(inputs_open_data[i-60:i,0])\n",
    "    X_open_test=np.array(X_open_test)\n",
    "\n",
    "    X_open_test=np.reshape(X_open_test,(X_open_test.shape[0],X_open_test.shape[1],1))\n",
    "    prediction_opening=lstm_model.predict(X_open_test)\n",
    "    prediction_opening=scaler.inverse_transform(prediction_opening)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #high\n",
    "    X_high_test=[]\n",
    "    for i in range(60,inputs_high_data.shape[0]):\n",
    "        X_high_test.append(inputs_high_data[i-60:i,0])\n",
    "    X_high_test=np.array(X_high_test)\n",
    "\n",
    "    X_high_test=np.reshape(X_high_test,(X_high_test.shape[0],X_high_test.shape[1],1))\n",
    "    prediction_high=lstm_model.predict(X_high_test)\n",
    "    prediction_high=scaler.inverse_transform(prediction_high)\n",
    "\n",
    "\n",
    "    #low\n",
    "    X_low_test=[]\n",
    "    for i in range(60,inputs_low_data.shape[0]):\n",
    "        X_low_test.append(inputs_low_data[i-60:i,0])\n",
    "    X_low_test=np.array(X_low_test)\n",
    "\n",
    "    X_low_test=np.reshape(X_low_test,(X_low_test.shape[0],X_low_test.shape[1],1))\n",
    "    prediction_low=lstm_model.predict(X_low_test)\n",
    "    prediction_low=scaler.inverse_transform(prediction_low)\n",
    "\n",
    "    #close\n",
    "    X_close_test=[]\n",
    "    for i in range(60,inputs_close_data.shape[0]):\n",
    "        X_close_test.append(inputs_close_data[i-60:i,0])\n",
    "    X_close_test=np.array(X_close_test)\n",
    "\n",
    "    X_close_test=np.reshape(X_close_test,(X_close_test.shape[0],X_close_test.shape[1],1))\n",
    "    prediction_closing=lstm_model.predict(X_close_test)\n",
    "    prediction_closing=scaler.inverse_transform(prediction_closing)\n",
    "\n",
    "    lstm_model.save(\"saved_lstm_model.h5\")\n",
    "\n",
    "    valid_open_data[\"Predictions\"] = prediction_opening\n",
    "\n",
    "    valid_high_data = pd.DataFrame(index=range(0, len(prediction_high)), columns=[\"Predictions\"])\n",
    "\n",
    "    # for i in range(0,len(prediction_opening)):\n",
    "    valid_high_data[\"Predictions\"] = prediction_high\n",
    "\n",
    "    valid_low_data = pd.DataFrame(index=range(0, len(prediction_low)), columns=[\"Predictions\"])\n",
    "\n",
    "    # for i in range(0,len(prediction_opening)):\n",
    "    valid_low_data[\"Predictions\"] = prediction_low\n",
    "\n",
    "    valid_close_data = pd.DataFrame(index=range(0, len(prediction_closing)), columns=[\"Predictions\"])\n",
    "\n",
    "    # for i in range(0,len(prediction_opening)):\n",
    "    valid_close_data[\"Predictions\"] = prediction_closing\n",
    "\n",
    "    # valid_open_data[\"Predictions\"].dtypes\n",
    "\n",
    "    train_close_data=new_close_dataset[:train_value]\n",
    "    valid_close_data=new_close_dataset[train_value:]\n",
    "    valid_close_data['Predictions']=prediction_closing\n",
    "    plt.plot(train_close_data[\"Close\"])\n",
    "    plt.plot(valid_close_data[[\"Close\",\"Predictions\"]]) # prediction-blue\n",
    "    plt.plot(valid_close_data[[\"Predictions\"]])\n",
    "\n",
    "    import datetime\n",
    "\n",
    "    base = datetime.date.today()\n",
    "    for x in range(0, remain_value):\n",
    "        valid_open_data['Date'][x] = (base + datetime.timedelta(days=x))\n",
    "\n",
    "    # Calling DataFrame constructor\n",
    "    df = pd.DataFrame({\n",
    "        'Date': [i for i in valid_open_data['Date']],\n",
    "        'Open': [i for i in valid_open_data['Predictions']],\n",
    "        'High': [i for i in valid_high_data['Predictions']],\n",
    "        'Low': [i for i in valid_low_data['Predictions']],\n",
    "        'Close': [i for i in valid_close_data['Predictions']],\n",
    "\n",
    "    })\n",
    "\n",
    "    # convert into datetime object\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    # apply map function\n",
    "    df['Date'] = df['Date'].map(mpdates.date2num)\n",
    "\n",
    "    # creating Subplots\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    # plotting the data\n",
    "    candlestick_ohlc(ax, df.values, width=0.6,\n",
    "                     colorup='green', colordown='red',\n",
    "                     alpha=0.8)\n",
    "\n",
    "    # allow grid\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Setting labels\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Price')\n",
    "\n",
    "    # setting title\n",
    "    plt.title('Prices For the Period 10-05-2021 to 03-06-2021')\n",
    "\n",
    "    # Formatting Date\n",
    "    date_format = mpdates.DateFormatter('%d-%m-%Y')\n",
    "    ax.xaxis.set_major_formatter(date_format)\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # show the plot\n",
    "\n",
    "    STOCK = BytesIO()\n",
    "    plt.savefig(STOCK, format=\"png\")\n",
    "    STOCK.seek(0)\n",
    "    plot_url = base64.b64encode(STOCK.getvalue()).decode('utf8')\n",
    "    return render_template(\"plot.html\", plot_url=plot_url)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
